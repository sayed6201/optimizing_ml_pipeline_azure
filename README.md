# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary

This dataset contains data about marketing campaigns based on phone calls of a Portuguese banking institution. We seek to predict to predict if the client will subscribe a term deposit.

The best perfoming model was Voting Ensemble model having accuracy 91.56 % followed by MaxAbsScaler, LightGBM having accuracy of 91.39%. The best performing model was derived using Azure AutoML.
The same dataset was also used to train Logistic regression model and Parameters were tuned using Azure Hyperdrive which resulted in 91.32% accuracy.

## Scikit-learn Pipeline

### The pipeline architecture
* The tabular dataset is created using TabularDatasetFactory from the the link
* The dataset is cleaned using python script. cleaning includes encoding categorical values, representing some non numeric values into numeric format 
* The data is splitted into test and train set. the test:train ration is 20:80
* The data is used to train LogisticRegression from sklearn.linear_model. SKLearn estimator from azureml.train.sklearn is used to run the trainnig script
* The model LogisticRegression takes two hyperparameters inverse of regularization strength (--C) and Max iterations (--max_iter), Using Azure Hyper Drive this paremeters are tuned to get model with best accuracy.


### Benefits of choosing Random Parameter Sampler
* Parameter sampling method helps us to choose proper hyperparameter value for our model, in Azure Machine Learning supports the following methods:
    * Random sampling
    * Grid sampling
    * Bayesian sampling
I opted Random sampling method.
* In random sampling, hyperparameter values are randomly selected from the defined search space. It also supports early termination of low-performance runs.
    * The discrete values chosen for inverse of regularization strength were 0.01,5,20,100,500, where the lower value indicates strong regularization, and the best model had inverse of regularization strength of 0.01.
    * The discrete values chosen for Max iteration were 10,50,100,150,200. the best model had Max iteration of 150.


### Benefits of choosing Bandit Policy for early stopping
* The early stopping policies automatically terminate poorly performing runs and improves computational efficiency.
* Bandit policy is based on slack factor and evaluation interval. I have defined slackfactor = 0.1, The policy terminates runs where the primary metric is not within the specified slack factor compared to the best performing run.


## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
* Automated machine learning or AutoML is the process of automating some of the the iterative tasks and time consuming of machine learning pipeline such as feature engineering, hyperprameter tuning, model training etc.

* To configure AutoML i have specified following parameters in AutoMLConfig class from azureml.train.automl.
   * task: refers to problem The type of task to run, we are solving a classification problem
   * primary_metric: The metric that AutoML will optimize for model selection. I'm specifying 'Accuracy'
   * n_cross_validations: Number of cross validations to be performed, I'm specifying 'Accuracy'
   * training_data: data to be used for training the model.
   * max_concurrent_iterations : Rrefers to the maximum number of iterations executed in parallel, i have spevified 4
   * enable_early_stopping: if set true it will early terminate if the score is not improving. 
   * label_column_name : label of column that will be predicted.
   * max_cores_per_iteration: Refers to The maximum number of threads to be used for training iteration.I'm specyfying -1, which refers to use all the possible cores per iteration per child-run.
   * experiment_timeout_minutes : i specified 30 minutes which means maximum amount of time that all iterations combined can take before the experiment terminates.
[pic]

* Both AutoML and HyperDrive was configured with same dataset and same primary metric. AutoML was able to train model having the best accuracy. the screenshot below shows models with best accuracy in descending order. VotingEnsemble model outperformed all other models, scoring accuracy of 91.56 %.
[pic]

* From the trained model explanation we can understand what features are having greater impact on decision making, from the screenshot below we can see that employment variation rate, month, number of employees , duration, pdays etc has higher importance in prediction
[pic]

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
